---
title: "Survival Analysis of Factors Affecting Time on Market for Twin Cities Homes"
author: "Nick McMullen, April Choi"
date: "April 20, 2018"
output:
  pdf_document:
    pandoc_args: [
      "-V", "classoption=twocolumn" ]
  html_document: default
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readr)
library(ggplot2)
library(survival)
library(survminer)

house <- read_csv("../Source/house_TC.csv")
house <- house %>% mutate(tom = ifelse(tom == 0, 1, tom),
                          prdiff_np = as.factor(prdiff_np))
```

## 1 | Introduction


### 1.1 Background

The real estate market in the Twin Cities (Minneapolis and St. Paul, MN, USA), and many places across the United States, has been thriving on the economic recovery since the end of the Great Recession. While the current market is, to the casual observer, favorable to sellers some houses in Twin Cities still take a surprisingly long time to sell. We will investigate the characteristics that impact time on market (TOM) for houses in the Twin Cities through a survival analysis, or time-to-event, framework.


### 1.2 Review of Literature

\textbf{Price}

One of the most obvious factors that may influence TOM for any house is price. A high price may scare potential buyers away, while a low price might invite skepticism or a long bidding war. The "right" pricing decision is a difficult one to make for sellers and agents, but reaching an equilibrium between buyer and seller satisfaction may be the best way to minimize TOM. Cheng, Lin, and Liu (2008) developed a closed-form formula to uncover the theoretical relationship between price and TOM. They aim to describe the marginal benefit of keeping a house on the market longer.

The authors used house sales data from Fannie Mae and Freddie Mac, U.S. federal mortgage agencies, and identified a nonlinear positive relationship between price and TOM. They approached this analysis by assuming that a buyer and seller arrive at an agreed upon price following the Poisson processes at rate $\lambda$. While utilizing methods from Bond et al. (2007), they investiaged some assumptions about the shape of TOM data, including normal, chi-square, Weibull, and exponential distributions. Like Bond et al. (2007), Cheng, Lin, and Liu (2008) found that the exponential distribution best fit the TOM data. 

The findings from Cheng, Lin, and Liu's (2008) investigation was that marginal benefit on sale price decreases after each offer that is made on a house. As a house's price approaches equilibrium between seller and buyer satisfaction, it does the seller little good to leave the house on the market longer.

\textbf{Duration Dependence}

Another interesting question regarding TOM is how the probability of sale changes with time. Thomas W. Zuehlke (1987) conducted research on this very topic. He used 290 single family detached homes obtained from a 1982 multiple listing service (MLS) book in Tallahassee, FL, USA and observed how likely each house was to sell based on its vacancy status. Zuehlke utilized a Weibull hazard model to compare the two and found that sellers of vacant houses have stronger incentives to reduce prices faster than those of occupied houses. Thus, Zuehlke finds that vacant houses tend to exhibit positive duration dependence, while occupied homes show little evidence of duration dependence. 

Motivated by a Massachusetts state policy adopted in 2006 that prohibits sellers from resetting their home's TOM by relisting, Tucker, Zhang, and Zhu (2013) also investigated the impact of TOM on sale price. The authors agree that longer TOM is negatively associated with buyer perception, which lines up with the Massachusetts relisting policy. To investigate if TOM was indeed a significant deterrent for buyers looking at an otherwise appealing house, the authors analyzed the TOM for homes before and after the enactment of the policy. They obtained listings data for residential properties on the market between January 2005 and June 2007 from two MLSs: MLS-PIN, which serves Massachusetts, and the State-Wide Rhode Island MLS. Their analysis consisted of three groupings of homes: listed and sold before the policy change, listed before and sold after, and listed and sold after. The authors utilized simple linear regression between the three groups and found that the homes listed before the policy and sold after were most severely impacted, resulting in an average sale price reduction of $16,000. 

\textbf{Listing Price Changes}

Listing price changes may also affect the TOM for a house. A listing price change could attract more attention to a house on the market, but could also indicate a longer TOM. John R. Knight (2002) conducted an analysis on listing price changes, investigated which types of homes were most likely to go through multiple listing price changes, and which price changes tend to give the worst results for the seller.

Knight used 3490 detached single family homes that sold between January 1997 and December 1998 by Metroservices Inc. of Sacramento, CA, USA. He notes that price adjustment data is generally missing from TOM datasets, but his study incorporated the price changes into the analysis to examine the determinants of list price changes. He utilized a maximum likelihood probit model and found that the two most important determinants of price changes are TOM and initial markup. Atypical homes tend to not see significant price changes because there is little market precedent for price changes after a certain TOM. Knight's findings are consistent with previous research on pricing under demand uncertainty. 


### 1.3 Research Question (and mapping paragraph)

We are interested in investigating the factors that affect the TOM for a single family homes in the Twin Cities (Minneapolis and Saint Paul) that were sold between July 26, 2017 and February 1, 2018. Some variables of interest include the amount of recorded crime in a house's designated neighborhood and the proximity of a house to the nearest school. 

In the following sections, we outline our data collection and methods and provide a brief description of our assumptions. 

##2 | Data and Methods

### 2.1 Data and Sources

#### Real Estate Data

Our data represents a random sample of 311 single family homes in the Twin Cities that were sold between July 26th, 2017 and February 1st, 2018. A search of all recently sold homes in the area was conducted in the Coldwell Banker MLS and 311 unique addresses were randomly selected for the project. Some variables were scraped directly from the Coldwell Banker site, while others were manually inputted. 

#### Crime Data

We also obtained crime data beginning on January 1, 2015 from the government websites for the cities of Minneapolis and St. Paul. Each crime was matched with a neighborhood, aggregated into total neighborhood crime counts, and then joined with the house sales data. This addition will provide insight on the number of crimes that have been recorded over the past three years near each sold house. 

### 2.2 Variables

For all 311 observations, we collected unique addresses `address`, city of residence `city`, zip code `zip`, number of bedrooms `beds`, number of full bathrooms `bathf`, number of partial bathrooms `bathp`, number car garage `carg`, house squarefeet `sqft`, price the home was listed at `listedatpr`, price the home was sold for `soldatpr`, date the home was listed `listedatdate`, date the home was sold `soldatdate`, neighborhood the house is located `neighb`, distance to nearest school (mi.) `schdist`, and number of crimes that were recorded in that neighborhood beginning on January 1, 2015 `ncrime`. We also calculated the time on market `tom` for each house from list date to sale date, included the property ID `pid` from the Coldwell Banker website, calculated a price difference from list price to sale price `prdiff`, computed a percent change price `prdiff_perc`, and created a categorical variable `prdiff_np` to reflect whether a house had a positive (1), negative (2), or neutral (3) price difference. 

### 2.3 Assumptions

An essential assumption to our research is based on censoring. We intentionally collected our data from a sample of recently sold houses to limit censoring. If we were to take a true random sample of all houses listed for sale in the past $X$ number of years, we realize that a significant amount of right censoring could be present, because at the time of data collection some houses in our sample would have not been sold yet. We acknowledge that sampling from a set of recently sold houses may introduce some bias into our results - all recently sold houses in this particular date range (late January to early Februray 2018) may share certain unknown or unaccounted-for characteristics that made them sell. This bias is acceptable considering the convenience and added accuracy provided by uncensored data.

### 2.4 Methods

We utilize visualizations of parametric and non-parametric estimates of the true survival curve for `Time on Market (tom)` and test for significant differences in `tom` among houses with different characteristics, such as the price difference between list and sold price. 

##3 | Preliminary Results

We begin our preliminary analysis by investigating the length of time that houses in the Twin Cities remain on the market after their preliminary listing date.

### 3.1 Non-Parametric Survival Curve Estimates for Aggregate Data

#### Kaplan-Meier

First, we fit a Kaplan-Meier curve with confidence intervals for survival (time on market) across all groups. Since the data contains no censoring, Kaplan-Meier is equivalent to `1-ecdf` representative of the raw data itself. From the data, the mean is approximately 85.97 days, the median is 73 days, and the 95% CI is [66, 82]. The curve is right-skewed, indicating that there are more houses that sell faster than average. 

```{r echo=FALSE}

# mean(house$tom)
# median(house$tom)
KM = survfit( Surv(tom) ~ 1 , conf.type="plain" , data=house ) 
ggsurvplot(KM, data=house) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Kaplan-Meier Curve of Days on Market")

```

### 3.2 Univariate Models

#### School Distance 

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ schdist , dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist , dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ schdist , data = house )

summary(mw) # the sign of schdist makes sense (positive) and it is significant
summary(mln) # the sign of schdist is negative and it is NOT significant
mcox # sign agrees with weibull and it is significant
```

* Weibull: the sign of schdist makes sense (positive) and it is significant
* Log Normal: the sign of schdist is negative and it is NOT significant; the time on market is longer the greater the school distance from the property
* Cox PH: sign agrees with weibull and it is significant; The hazard decreases by 0.701 times for each increase in mile.


#### Crime Continuous

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ ncrime, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ ncrime, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ ncrime , data = house )

summary(mw)
summary(mln)
mcox
```

* Not significant for any of the model


#### Crime Categorical

```{r echo=FALSE, include=FALSE}
house$crimeCat2 = cut(house$ncrime, breaks = c(0,250,2000,5000,10000))

mw = survreg( Surv(tom) ~ crimeCat2, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ crimeCat2, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ crimeCat2, data = house )

summary(mw)
summary(mln)
mcox
```

* Weibull

The second group, (250, 2000], has boarderline significance at 10% level, and the third group, (2000, 5000], is significant at 0.05%. Compared to the first group, (0,250], the (250, 2000] group is more likely to stay on market by exp(0.14) (!!!) times, and the next group, (2000, 5000] is likely to stay on market by approximately double the duration of the (250, 2000] group at exp(0.28). The fact that the houses in the neighborhoods with less crime ((250, 2000]) would sell faster (time on market is shorter) than those in the neighborhoods with more crime ((2000, 5000]) makes sense since people generally prefer neighborhoods with less crime. However, the highest crime category ((5000, 10000]) has almost no difference compared to the lowest crime category, possibly due to more affordability. In other words, neighborhoods with the highest crime rate may also tend to be more affordable. 

* Log Normal

Not significant again.

* Cox PH

Cox PH agrees with Weibull. The hazard ratio for the (250, 2000] group is 0.81 times that of the (0,250] group. The hazard ratio for the (2000, 5000] group is 0.64 times that of the (0,250] group. Finally, the hazard ratio for the (5000, 10000] group is 0.94 times that of the (0,250] group. 


#### Listed At Date

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ listedatdate, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ listedatdate, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ listedatdate, data = house )

summary(mw)
summary(mln)
mcox
```

* Weibull and Log Normal

Both Weibull and Log normal has a negative coefficient with extreme significance, which means that time on market decreases by each increase in the listed date. We may be led to say that as time progresses, the real estate market is getting hot (houses are selling faster; it's a seller's market), but we should be careful as our data contains only those houses that are sold (!!!). Thus, the properties with listed date that are more recent must have shorter time on market.

* Cox PH 

The HR gets multiplied by 1.14 each time the listed at date increases by 1. In other words, the risk of being sold gets larger the later the listed date. The p-value is significant.

### 3.3 Multivariate Models

#### Crime Category 2 + Listed at Price + School Distance
#### Without Interaction Term (Original)

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ schdist + ncrime + listedatdate + log(listedatpr) , dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist + ncrime + listedatdate + log(listedatpr) , dist = "lognormal" , data = house )

summary(mw) # schdist sign
summary(mln) # schdist insign (Victor!!!)
```


Model Interpretations:

Weibull:

- School distance has a negative multiplicative effect on time on market by $e^{-.026}$ with a p-value of $.375$. This is not a significant result.

- Number of crimes in the neighborhood has a positive multiplicative effect on time on market of $e^{.00000649}$ with a p-value by $.0959$. This is also not a significant result.

- The date at which the house was listed has a negative multiplicative impact on the time on market by $e^{-.0105}$ with a p-value of $0$. This makes sense because as we progress one date forward, we are getting closer to the time at which a house was sold since we only included sold houses in our data. CHECK -- Is this necessary to include?

- The log of the price at which a house was listed has a positive multiplicative impact on the time on market by $e^{.0646}$ with a p-value of $.00191$. This is a significant result. This model shows that for every dollar a house's log list price increases, the time on market for that house is expected to increase by about $6.6732$%. 


Lognormal:

- School distance has a negative multiplicative effect on time on market by $e^{-.177}$ with a p-value of $.00087$. This is a significant result. This model shows that for every mile farther a house is away from the nearest school, the time on market is expected to decrease by about $16.332$%.

- Number of crimes in the neighborhood has a positive multiplicative effect on time on market of $e^{.0000124}$ with a p-value by $.0927$. This is not a significant result.

- The date at which the house was listed has a negative multiplicative impact on the time on market by $e^{-.0102}$ with a p-value of $0$. This makes sense because as we progress one date forward, we are getting closer to the time at which a house was sold since we only included sold houses in our data. CHECK -- Is this necessary to include?

- The log of the price at which a house was listed has a positive multiplicative impact on the time on market by $e^{.0702}$ with a p-value of $.05$. This is a significant result at the 5% level. This model shows that for every dollar a house's log list price increases, the time on market for that house is expected to increase by about $7.2723$%. 


*Hypotheses*

Now we must decide which model is better. To do this, we will first plot the Cox-Snell residuals for the Weibull and Lognormal models and then compare the AIC calculations for each model.

* Ho: weibull: tom ~ beds + bathf + bathp + carg + sqft + schdist + ncrime + prdiff
* Ha: lognorm: tom ~ beds + bathf + bathp + carg + sqft + schdist + ncrime + prdiff


*Cox-Snell Residuals*

Log-normal looks the best!

```{r echo=FALSE, include=FALSE}
# Creates Cox-Snell Plot:
CoxSnell = function(cs, status, xlim=NULL, ylim=NULL) {
  kmcs=survfit(Surv(jitter(cs,amount=(max(cs)-min(cs))/1000),status)~1)$surv
  plot(log(-log(kmcs))~sort(log(cs)),xlab="log(Cox-Snell)",ylab="log(-log(S(Cox-Snell)))",xlim=xlim,ylim=ylim)
  abline(0,1,col='red') }
```


```{r include=FALSE}

house$status <- rep(1, 311)

# Create Cox-Snell residuals
CS_e = -log( 1 - pexp(house$tom, 1/exp(4.153050e+00 + 5.260030e-02*house$beds + 4.625418e-02*house$bathf + 3.530967e-02*house$bathp + -4.039299e-02*house$carg -2.186615e-05*house$sqft + 1.252779e-01*house$schdist + 5.489057e-06*house$ncrime + -5.267278e-06*house$prdiff) ) )
CS_w = -log( 1 - pweibull(house$tom, 1/0.532846, exp(4.153050e+00 + 5.260030e-02*house$beds + 4.625418e-02*house$bathf + 3.530967e-02*house$bathp + -4.039299e-02*house$carg -2.186615e-05*house$sqft + 1.252779e-01*house$schdist + 5.489057e-06*house$ncrime + -5.267278e-06*house$prdiff ) ) )
CS_ln = -log( 1 - plnorm(house$tom, 4.153050e+00 + 5.260030e-02*house$beds + 4.625418e-02*house$bathf + 3.530967e-02*house$bathp + -4.039299e-02*house$carg -2.186615e-05*house$sqft + 1.252779e-01*house$schdist + 5.489057e-06*house$ncrime + -5.267278e-06*house$prdiff, 0.5914082) ) 

# Make appropriate graph using CoxSnell function
CoxSnell( CS_w , house$status )
CoxSnell( CS_ln , house$status )
```

The lognormal model appears to perform better when evaluating performance graphically.

*AIC*

Lognormal (3240.594) performs better in the AIC calculation than Weibull (3241.18). 

```{r echo=FALSE, include=FALSE}
mln$loglik

2*(10--1610.590) # mw
2*(10--1610.297) # mln
```

#### With Interaction Term

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ crimeCat2 + I(log(listedatpr)) + schdist, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ crimeCat2 + I(log(listedatpr)) + schdist, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ crimeCat2 + I(log(listedatpr)) + schdist , data = house )

summary(mw)
summary(mln)
mcox
```

* General

The model now has an interaction of the listed price variable which we hypothesized, should be a control for the crime variable. In the earlier analysis, we saw that the highest crime group did not show a difference in time on market compared to the lowest crime group, and we reasoned that one of the possible sources may be price. Holding all other variables equal, the highest crime variable is now more positive in coefficient despite the still insignificant p-value. Also, we see that all other variables are too significant and have expected signs. 

* Weibull

Similar to previous univariate analysis with crime category variable, the second group is more likely to stay on market longer compared to the first group, although the third group does not quite double in its market duration compared to the second group as it did in the univariate analysis. However, the second and third group both are now significant at the 5% level, and the highest crime group is still insignificant although the p-value decreased by a factor of 3. The listed price interaction variable is significant with positive coefficient; in other words, homes with the higher listed price tend to stay on market longer. The school distance is also positive with a significant p-value, meaning that the homes farther away from schools tend to stay on the market longer. Compared to the previous Weibull model with no interaction term, this makes sense. Houses closer to schools tend to be in more populated, desirable areas to live, so it should follow that houses closer to a school would sell faster. 

* Log Normal 

Most are similar to Weibull except more variables are insignificant. The school distance variable is still largely insignificant. 

* Cox PH

Outputs agree with Weibull. All are significant except for the highest crime category.









### 3.3 Non-Parametric Statistiscal Tests

#### List and Sale Price Difference

#### Log-Rank Test

In order to determine if the differences in the estimated survival curves for this category are statistically significant, we conduct a log-rank test. The results are as follows:

$$H_0: S_1(t) = S_2(t) = S_3(t) \ \forall \ t$$

The TOM distributions for the three price-difference conditions are identical at all time points.

$$H_A: S_1(t) \neq S_2(t) \neq S_3(t) \ \text{for some} \ t$$

The TOM distributions for the three price-difference conditions differ at at least one time point.

```{r echo=FALSE, include=FALSE}

survdiff(Surv(tom) ~ as.factor(prdiff_np), data=house)

```

A log-rank test reveals a Mantel-Cox test statistic of $53.87$. This produces a p-value of nearly 0:

```{r echo=FALSE}

1 - pchisq(37.71+10.75+5.41, df=2)

```

Thus, we confidently reject the null hypothesis and conclude that the three survival curves for price difference (negative, zero, positive) differ for some `tom`. 

#### Hazard Ratio

Now, we compare the risk of failures (being sold) between two groups at a time by examining the hazard ratios. The first comparison is between the high-demand and low-demand homes. The hazard ratio is

```{r echo=FALSE}
# Note: + = hot houses
(HR = (81/41.5)/(193/244.2)) # + / -
```

and the confidence interval is

```{r echo=FALSE}
cat("[", HR*exp(-1.96*sqrt(1/41.5+1/244.2)), ", ", HR*exp(+1.96*sqrt(1/41.5+1/244.2)),"]", sep="")
```

The hazard ratio indicates that the probability of high-demand houses being sold is 2.47 times higher than that for low-demand houses. The confidence interval suggests that this hazard estimate is significant since the interval does not bound 1.


Next, we see the difference between low-demand and neutral-demand homes. The hazard ratio is

```{r echo=FALSE}
(HR = (193/244.2)/(37/25.3)) # - / 0
```

and the confidence interval is

```{r echo=FALSE}
cat("[", HR*exp(-1.96*sqrt(1/244.2+1/25.3)), ", ", HR*exp(+1.96*sqrt(1/244.2+1/25.3)),"]", sep="")
```

Hazard ratio shows that low-demand homes have around half the chance of being sold on the market compared to neutral-demand homes. Since the confidence interval does not encompass 1, the hazard estimate is significant.


Last, we compare high-demand and neutral-demand homes. The hazard ratio is

```{r echo=FALSE}
# Note: + = hot houses
(HR = (81/41.5)/(37/25.3)) # + / 0
```

and the confidence interval is

```{r echo=FALSE}
cat("[", HR*exp(-1.96*sqrt(1/41.5+1/25.3)), ", ", HR*exp(+1.96*sqrt(1/41.5+1/25.3)),"]", sep="")
```

Despite the hazard ratio of 1.33, the interval estimate suggests that the this difference of 1.33 is insignificant. This result is inconsistent with the significant p-value we obtained from the log-rank test.

Examining the confidence intervals of the three groups from the Kaplan-Meier curves, we see that high-demand and equilibrium houses lay on top of each other almost completely until around 40 days, and the confidence intervals overlap until approximately 175 days, which explain the insignificance in the hazard ratio estimate. On the other hand, low-demand and high-demand homes are quite distinctive and separate from each other with only a few spots where the confidence intervals intersect. This distinct separation is also reflective of the large hazard ratio (2.47) with confidence interval way greater than 1 ([1.777065, 3.431999]). 
