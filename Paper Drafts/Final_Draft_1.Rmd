---
title: "Survival Analysis of Factors Affecting Time on Market for Twin Cities Homes"
author: "Nick McMullen, April Choi"
date: "April 20, 2018"
output:
  pdf_document:
    pandoc_args:
    - -V
    - classoption=twocolumn
  html_document: default
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readr)
library(ggplot2)
library(survival)
library(survminer)
library(stargazer)

house <- read_csv("../Source/house_TC.csv")
house <- house %>% mutate(tom = ifelse(tom == 0, 1, tom),
                          prdiff_np = as.factor(prdiff_np))


# Creates Cox-Snell Plot:
CoxSnell = function(cs, status, xlim=NULL, ylim=NULL, main=NULL, sub=NULL) {
  kmcs=survfit(Surv(jitter(cs,amount=(max(cs)-min(cs))/1000),status)~1)$surv
  plot(log(-log(kmcs))~sort(log(cs)),xlab="log(Cox-Snell)",ylab="log(-log(S(Cox-Snell)))",xlim=xlim,ylim=ylim, main=main, sub=sub)
  abline(0,1,col='red') }

house$status <- rep(1, 311)

```

## 1 | Introduction


### 1.1 Background

The real estate market in the Twin Cities (Minneapolis and St. Paul, MN, USA), and many places across the United States, has been thriving on the economic recovery since the end of the Great Recession. While the current market is, to the casual observer, favorable to sellers some houses in Twin Cities still take a surprisingly long time to sell. We will investigate the characteristics that impact time on market (TOM) for houses in the Twin Cities through a survival analysis, or time-to-event, framework.


### 1.2 Review of Literature

\textbf{Price}

One of the most obvious factors that may influence TOM for any house is price. A high price may scare potential buyers away, while a low price might invite skepticism or a long bidding war. Moreover, a high price limits the number of potential buyers even if the price appropriately reflects the quality of the property. The "right" pricing decision is a difficult one to make for sellers and agents, but reaching an equilibrium between buyer and seller satisfaction may be the best way to minimize TOM. Cheng, Lin, and Liu (2008) developed a closed-form formula to uncover the theoretical relationship between price and TOM. They aim to describe the marginal benefit of keeping a house on the market longer.

The authors used house sales data from Fannie Mae and Freddie Mac, U.S. federal mortgage agencies, and identified a nonlinear positive relationship between price and TOM. They approached this analysis by assuming that a buyer and seller arrive at an agreed upon price following the Poisson processes at rate $\lambda$. While utilizing methods from Bond et al. (2007), they investiaged some assumptions about the shape of TOM data, including normal, chi-square, Weibull, and exponential distributions. Like Bond et al. (2007), Cheng, Lin, and Liu (2008) found that the exponential distribution best fit the TOM data. 

The findings from Cheng, Lin, and Liu's (2008) investigation was that marginal benefit on sale price decreases after each offer that is made on a house. As a house's price approaches equilibrium between seller and buyer satisfaction, it does the seller little good to leave the house on the market longer.

\textbf{Duration Dependence}

Another interesting question regarding TOM is how the probability of sale changes with time. Thomas W. Zuehlke (1987) conducted research on this very topic. He used 290 single family detached homes obtained from a 1982 multiple listing service (MLS) book in Tallahassee, FL, USA and observed how likely each house was to sell based on its vacancy status. Zuehlke utilized a Weibull hazard model to compare the two and found that sellers of vacant houses have stronger incentives to reduce prices faster than those of occupied houses. Thus, Zuehlke finds that vacant houses tend to exhibit positive duration dependence, while occupied homes show little evidence of duration dependence. 

Motivated by a Massachusetts state policy adopted in 2006 that prohibits sellers from resetting their home's TOM by relisting, Tucker, Zhang, and Zhu (2013) also investigated the impact of TOM on sale price. The authors agree that longer TOM is negatively associated with buyer perception, which lines up with the Massachusetts relisting policy. To investigate if TOM was indeed a significant deterrent for buyers looking at an otherwise appealing house, the authors analyzed the TOM for homes before and after the enactment of the policy. They obtained listings data for residential properties on the market between January 2005 and June 2007 from two MLSs: MLS-PIN, which serves Massachusetts, and the State-Wide Rhode Island MLS. Their analysis consisted of three groupings of homes: listed and sold before the policy change, listed before and sold after, and listed and sold after. The authors utilized simple linear regression between the three groups and found that the homes listed before the policy and sold after were most severely impacted, resulting in an average sale price reduction of $16,000. 

\textbf{Listing Price Changes}

Listing price changes may also affect the TOM for a house. A listing price change could attract more attention to a house on the market, but could also indicate a longer TOM. John R. Knight (2002) conducted an analysis on listing price changes, investigated which types of homes were most likely to go through multiple listing price changes, and which price changes tend to give the worst results for the seller.

Knight used 3490 detached single family homes that sold between January 1997 and December 1998 by Metroservices Inc. of Sacramento, CA, USA. He notes that price adjustment data is generally missing from TOM datasets, but his study incorporated the price changes into the analysis to examine the determinants of list price changes. He utilized a maximum likelihood probit model and found that the two most important determinants of price changes are TOM and initial markup. Atypical homes tend to not see significant price changes because there is little market precedent for price changes after a certain TOM. Knight's findings are consistent with previous research on pricing under demand uncertainty. 


### 1.3 Research Question (and mapping paragraph)

We are interested in investigating the factors that affect the TOM for a single family homes in the Twin Cities (Minneapolis and Saint Paul) that were sold between July 26, 2017 and February 1, 2018. Some variables of interest include the amount of recorded crime in a house's designated neighborhood and the proximity of a house to the nearest school. 

In the following sections, we outline our data collection and methods and provide a brief description of our assumptions. 

##2 | Data and Methods

### 2.1 Data and Sources

#### Real Estate Data

Our data represents a random sample of 311 single family homes in the Twin Cities that were sold between July 26th, 2017 and February 1st, 2018. A search of all recently sold homes in the area was conducted in the Coldwell Banker MLS and 311 unique addresses were randomly selected for the project. Some variables were scraped directly from the Coldwell Banker site, while others were manually inputted. 

#### Crime Data

We also obtained crime data beginning on January 1, 2015 from the government websites for the cities of Minneapolis and St. Paul. Each crime was matched with a neighborhood, aggregated into total neighborhood crime counts, and then joined with the house sales data. This addition will provide insight on the number of crimes that have been recorded over the past three years near each sold house. 

### 2.2 Variables

For all 311 observations, we collected unique addresses `address`, city of residence `city`, zip code `zip`, number of bedrooms `beds`, number of full bathrooms `bathf`, number of partial bathrooms `bathp`, number car garage `carg`, house squarefeet `sqft`, price the home was listed at `listedatpr`, price the home was sold for `soldatpr`, date the home was listed `listedatdate`, date the home was sold `soldatdate`, neighborhood the house is located `neighb`, distance to nearest school (mi.) `schdist`, and number of crimes that were recorded in that neighborhood beginning on January 1, 2015 `ncrime`. We also calculated the time on market `tom` for each house from list date to sale date amd included the property ID `pid` from the Coldwell Banker website. 

### 2.3 Assumptions

An essential assumption to our research is based on censoring. We intentionally collected our data from a sample of recently sold houses to limit censoring. If we were to take a true random sample of all houses listed for sale in the past $X$ number of years, we realize that a significant amount of right censoring could be present, because at the time of data collection some houses in our sample would have not been sold yet. We acknowledge that sampling from a set of recently sold houses may introduce some bias into our results - all recently sold houses in this particular date range (late January to early Februray 2018) may share certain unknown or unaccounted-for characteristics that made them sell. This bias is acceptable considering the convenience and added accuracy provided by uncensored data.

### 2.4 Methods

We utilize visualizations of parametric and non-parametric estimates of the true survival curve for `Time on Market (tom)` and test for significant differences in `tom` among houses with different characteristics, such as the price difference between list and sold price. 

##3 | Preliminary Results

We begin our preliminary analysis by investigating the length of time that houses in the Twin Cities remain on the market after their preliminary listing date.

### 3.1 Non-Parametric (Kaplan-Meier) Survival Curve Estimates 

#### Proximity to Nearest School

Kaplan-Meier curves allow us to observe the general trends in the data, with time on market being the most important variable in the analysis. Our parametric analysis that follows will be informed by basic insights obtained from these Kaplan-Meier curves. 

First, we fit a Kaplan-Meier curve for time on market by distance from the nearest school. In order to do this, we identify the closest 50% of homes as "close" and the farthest 50% of homes as "far."

```{r echo=FALSE}

house$schdistCat <- cut(house$schdist, breaks = quantile(house$schdist, probs=c(0, .5, 1)))

KM0 <- survfit(Surv(tom) ~ schdistCat, conf.type="plain", data=house)

ggsurvplot(KM0, data=house, legend.labs=c("Near", "Far"), xlim=c(0,250)) + 
  labs(x = "Days on Market", y = "Survival Probability", title="Days on Market by Proximity to Nearest School")


```

There appears to be no difference based on distance to school. However, this may be due to the over-generalization (near vs. far) of school distance. This variable warrants further investigation. 

#### Crime 

Next, we fit a Kaplan-Meier curve for time on market based on number of crimes committed in that house's neighborhood since the beginning of 2015. 

```{r echo=FALSE}
house$crimeCat2 = cut(house$ncrime, breaks = c(0,250,2000,5000,10000))

# mean(house$tom)
# median(house$tom)
KM = survfit( Surv(tom) ~ crimeCat2, conf.type="plain" , data=house ) 
ggsurvplot(KM, data=house, legend.labs=c("0 to 250 crimes", "250 to 2000", "2000 to 5000", "5000 to 10000"), xlim=c(0,250)) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Days on Market by Crime Since 2015 Category")
```

We see that homes that fit into the second highest number of crimes category take the longest to sell, while homes in the lowest crime neighborhoods sell fastest. This progression seems logical, except for homes in the highest crime neighborhoods, which appear to sell generally the second fastest. This is likely because there are fewer houses (59) that fall into the highest crime category and thus the sample is not representative of the actual market. 

#### List Price

This Kaplan-Meier curve shows the time on market based on their list price. 

```{r echo=FALSE}
house$listedatprCat = cut(house$listedatpr, breaks = quantile(house$listedatpr, probs=c(0, .33, .67, 1)))

# mean(house$tom)
# median(house$tom)
KM1 = survfit( Surv(tom) ~ listedatprCat , conf.type="plain" , data=house ) 
ggsurvplot(KM1, data=house, legend.labs=c("price = 63,000 to 180,000", "180,000 to 275,000", "275,000 to 1,300,000")) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Days on Market by List Price Category")
```

Houses that fall into the highest price category appear to take the longest to sell, while houses in the middle price category appear to sell the fastest. 

#### Municipal Location

```{r echo=FALSE}
# mean(house$tom)
# median(house$tom)
KM2 = survfit( Surv(tom) ~ city , conf.type="plain" , data=house ) 
ggsurvplot(KM2, data=house, legend.labs=c("Minneapolis", "St. Paul")) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Days on Market by City")
```

There doesn't apprear to be a huge difference in time to sale between homes in St. Paul and Minneapolis, but we see that in our data, St. Paul homes take slightly longer to sell based on this Kaplan-Meier curve. While this relationship may seem negligible, this small difference warrants further investigation in parametric models. 

Now that we have taken a brief look at Kaplan-Meier curves for these variables, we will create some models with parametric assumptions to verify or refute previously observed trends by assessing for significant relationships. 


### 3.2 Univariate Parametric Models

#### Proximity to Nearest School

The Kaplan-Meier curve shown in the previous section revealed what appears to be no difference in how long a house takes to sell based on its municipal designation. In order to verify the previous graphical findings, we create three parametric models to further assess the impact of school distance on time to sale. 

```{r include=FALSE}
mw = survreg( Surv(tom) ~ schdist , dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist , dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ schdist , data = house )

summary(mw) # the sign of schdist makes sense (positive) and it is significant
summary(mln) # the sign of schdist is negative and it is NOT significant
mcox # sign agrees with weibull and it is significant
```


The Weibull model indicates that the properties that are farther from schools have longer TOM than those closer to schools, with a significant p-value. However, the log-normal model yields the opposite result with an insignificant p-value. This result may be due to the inherent differences in the two models, rather than the school distance variable being insignificant. In fact, the Cox PH model agrees with the Weibull model in the variable's direction and p-value. According to the Cox PH model, the hazard ratio of school distance is 0.701, which means that the risk of being sold decreases by 70% for every one-mile increase in school distance. In other words, properties farther away from schools take longer to sell.


```{r include = FALSE}
# Create Cox-Snell residuals
CS_w = -log( 1 - pweibull(house$tom, 1/0.537, exp(4.443 + 0.246*house$schdist) ) )
CS_ln = -log( 1 - plnorm(house$tom, 4.3010 + -0.0313*house$schdist, 0.623) ) 
```

```{r echo=FALSE} 
CoxSnell( CS_w , house$status, main="Weibull School Distance C-S Resids" )
CoxSnell( CS_ln , house$status ,xlim=c(-7,5), main="log-normal School Distance C-S Resids")
```

The log-normal Cox-Snell residuals appear to fit the model better since they fit the line with intercept 0 and slope 1 better.

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln

# The AIC for the Weibull model is 3242.878, and that for the log-normal model is 3258.564. Thus, we conclude that the Weibull model fits better than the log-normal model. 
```

AIC indicates that the Weibull model is a better fit. This contradiction between Cox-Snell residual plots and AIC could be attributed to... !!! (what could this be attributed to??)

This trend for Cox-Snell plots indicating that log-normal models are a better fit for the data continues throughout the univariate models below. Thus, we do not include the actual Cox-Snell residual plots going forward for univariate models. 



#### Crime 

```{r include=FALSE}
house$crimeCat2 = cut(house$ncrime, breaks = c(0,250,2000,5000,10000))

mw = survreg( Surv(tom) ~ crimeCat2, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ crimeCat2, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ crimeCat2, data = house )

summary(mw)
summary(mln)
mcox
```

Crime as a continuous variable was insignificant for all three models. Thus, we analyze the effect of crime as a categorical variable. Our categorical crime variable has four groups: crime count ranging from 0 to 250, 250 to 2000, 2000 to 5000, and 5000 to 10000.  

In the Weibull model, the 250-2000 crime group has TOM that is 14% longer than the 0-250 crime group, and the next group, the 2000-5000 crime group, has more than double the TOM of the previous group at 33%. While the p-value for 250-2000 crime group is at boarderline significance, that for the 2000-5000 crime group is significant at the 5% level. The fact that the houses in the neighborhoods with less crime (250-2000) would sell faster than those in the neighborhoods with more crime (2000-5000) makes sense since people generally prefer neighborhoods with less crime. 

On the other hand, the highest crime group (5000-10000) shows almost no difference in TOM compared to the lowest crime group, and its p-value is insignificant. This result is possibly due to the fact that properties located in high-crime neighborhoods tend to be more affordable. 

The Cox PH model agrees with the Weibull model. The hazard ratio for the 250-2000 crime group is approximately 19% less than that of the 0-250 crime group, and that for the (2000, 5000] group is approximately 36% less than that of the 0-250 crime group. Finally, the hazard ratio for the 5000-10000 crime group is only about 6% lower than the 0-250 crime group, again with insignificant p-value. The log-normal model too is insignificant. 

```{r include = FALSE}
CS_w = -log( 1 - pweibull(house$tom, 1/0.533, exp(4.45486375 +  0.13794492*(house$crimeCat2=="(250,2e+03]") + .28846076*(house$crimeCat2=="(2e+03,5e+03]") +   0.03853525*(house$crimeCat2=="(5e+03,1e+04]")     ) ) )
CS_ln = -log( 1 - plnorm(house$tom, 4.3010 + -0.0313*house$schdist, 0.623) ) 
```

```{r echo=FALSE, include=FALSE}
CoxSnell( CS_w , house$status, main="Weibull Crime Category C-S Resids")
CoxSnell( CS_ln , house$status, main="log-normal Crime Category C-S Resids")
```

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln
```

Again, the AIC indicates that the Weibull model is a better fit than the log-normal model. This is the same contradiction observed previously and can be attributed to... !!! (what can this be attributed to???)


#### List Price

```{r include=FALSE}
mw = survreg( Surv(tom) ~ log(listedatpr), dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ log(listedatpr), dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ log(listedatpr), data = house )

summary(mw)
summary(mln)
mcox
```

```{r include = FALSE}
exp(0.120) #w
exp(0.189) #ln
```

Properties with higher list price has a longer TOM at the 5% level significance for both Weibull and the log-normal models. The effect is stronger with the log-normal model at 20% longer TOM with a much higher significance (4.20e-03) compared to 12% longer TOM for the Weibull model with a slightly lower significance (3.48e-02). The results are consistent with the logic that a more expensive homes will take longer to sell. Despite the greater significance with a stronger effect, the AIC still yields a stronger evidence in support of the Weibull model over the log-normal model by a slight margin. (!!! too detailed?)

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln
```

#### City

```{r include=FALSE}
mw = survreg( Surv(tom) ~ city, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ city, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ city, data = house )

summary(mw)
summary(mln)
mcox
```

```{r include = FALSE}
exp(0.101)
exp(0.0602)
```

In the Weibull model, city of Saint Paul has a positive coefficient with a borderline insignificant p-value, indicating that properties in Saint Paul on average has 11% longer tom compared to those in Minneapolis. The log-normal model, on the other hand, was not at all significant with a very small effect. The Cox PH is in line with the Weibull model with hazard ratio of Saint Paul to Minneapolis being 0.86. This hazard ratio illustrates that the risk of being sold for a house in Saint Paul is 86% that for a house in Minneapolis, which translates into a longer tom for a house in Saint Paul than that in Minneapolis. 


```{r include = FALSE}
mw$coefficients
mln$coefficients
# Create Cox-Snell residuals
house$cityn = ifelse(house$city == "Minneapolis", 1, 0)
CS_w = -log( 1 - pweibull(house$tom, 1/0.548101, exp(4.5292418 + 0.1006498*house$cityn  ))) 
CS_ln = -log( 1 - plnorm(house$tom, 4.25681878 + 0.06020683*house$cityn, 0.6219641 ) ) 
```

```{r echo=FALSE}
CoxSnell( CS_w , house$status )
CoxSnell( CS_ln , house$status )
```

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln
```

Again, the Cox-Snell plot prefers the log-normal model, but the AIC results show otherwise.



### 3.3 Multivariate Parametric Models

#### School Distance, Crime Category, and List Price Without Interaction Term (Original)

```{r include=FALSE}
mw = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , dist = "lognormal" , data = house )
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , data = house )

summary(mw) 
summary(mln) 
mcox
```


```{r}
summary(mw)
mw$coefficients
exp(-.026)
```

If the price triples (mult by 2.81 or exp(1)), the probability of being sold is multiplied by 0.742. (Victor)

The model now has the list price variable as a control (!!!) for the crime variable. In the earlier analysis, we saw that the highest crime group did not show a difference in time on market compared to the lowest crime group, and we reasoned that one of the possible sources may be price. Holding all other variables equal, the highest crime variable is now more positive in its effect, with a slightly better p-value. Moreover, we see that all other variables have the expected signs and are significant at the 5% level. 

The Weibull model has similar results to the univariate crime category analysis previously conducted. The second crime group is more likely to stay on market longer compared to the lowest crime group in line with the univariate model. However, the tom for the third crime group is less than double that for the second crime group, which is a weaker effect than what we saw in the univariate analysis. With respect to p-values, both the second and third group are now significant at the 5% level, and the p-value for the highest crime group improved by a factor of 3. 

The list price variable is significant with positive coefficient; in other words, homes with the higher list price tend to stay on market longer. The school distance is also positive with a significant p-value, meaning that the homes farther away from schools tend to stay on the market longer. The directions with these two variables makes sense. Expensive houses are harder to sell because not many people are able to afford the house, and these houses may often be overpriced (higher than its appraisal value). On the other hand, houses closer to schools tend to be in more populated and desirable areas, so it should follow that houses closer to a school would sell faster. 

The log-normal model has similar directions as with the Weibull model but are insignificant. The Cox PH model outputs agree with Weibull, with all variables being significant except for the highest crime category.

#### Model Selection

Now, we select the model by first plotting the Cox-Snell residuals for the Weibull and log-normal models and then comparing the AIC calculations for each model. Utilizing both a graphical and analytical approach to assessing model fit will help ensure thorough vetting of models. 


*Cox-Snell Residuals*

```{r echo=FALSE}
mln$coefficients
# Create Cox-Snell residuals
CS_w = -log( 1 - pweibull(house$tom, 1/0.532846, exp(2.7119300 + 0.1843770*house$schdist +
                                                       0.1876134*(house$crimeCat2=="(250,2e+03]") +
                                                       0.2515044*(house$crimeCat2=="(2e+03,5e+03]") +
                                                       0.1093053*(house$crimeCat2=="(5e+03,1e+04]") +
                                                       0.1309947*log(house$listedatpr))))
CS_ln = -log( 1 - plnorm(house$tom, 1.37373386 + -0.04454097*house$schdist + 0.09386602*(house$crimeCat2=="(250,2e+03]") +
                           0.22584417*(house$crimeCat2=="(2e+03,5e+03]") + 0.16964559*(house$crimeCat2=="(5e+03,1e+04]") +
                           0.22797669*log(house$listedatpr), 0.6088315)) 

# Make appropriate graph using CoxSnell function
CoxSnell( CS_w , house$status , main = "Cox-Snell Residuals", sub = "Weibull Model")
CoxSnell( CS_ln , house$status , main = "Cox-Snell Residuals", sub = "Log-Normal Model")
```

The log-normal model appears to perform better when evaluating performance graphically.

```{r echo=FALSE, include=FALSE}
2*(10-mw$loglik[2]) # mw
2*(10-mln$loglik[2]) # mln
```


#### School Distance, Crime Category, and List Price With Interaction Term (if we need this vs. strata !!!)

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), dist = "lognormal" , data = house )
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), data = house )


summary(mw) 
summary(mln) 
mcox
```


*Summary of Cox Model*
!!!

```{r echo=FALSE, include=FALSE}
library(survminer)
fit = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , data = house )
fit
```

```{r echo=FALSE, warning=FALSE}
ggforest(fit, data = house)
```

```{r include = FALSE}
#stargazer(house[c(9,14,22),])
#stargazer(house[c(9,14,22),], summary=FALSE, rownames=FALSE)
stargazer(mw, mln, title="Results", align=TRUE)
#stargazer(mcox, title="Results", align=TRUE)
```








### 3.4 Testing the Cox PH Assumption

To test the PH assumption, we instead turn to examining the Kaplan-Meier c-log-log plot and the Schoenfeld residuals.


We first look at the PH assumption for the two cities: Saint Paul and Minneapolis. The very narrow gap in the two groups from the Kaplan-Meier c-log-log plot indicates essentially no difference between the two groups, providing a stronger evidence for the PH assumption.

```{r echo = FALSE}
KM = survfit(Surv(tom) ~ city, data=house)
plot(KM,fun='cloglog',mark.time=FALSE,col=1:2, xlim = c(15,220))
```

Similary, the constant residuals with essentially 0 rho and highly insignificant p-value in the Schoenfeld residual output indicates that the PH assumption is valid. In other words, it is safe to assume that the risk of being sold for a Saint Paul property over a Minneapolis property is constant over time, with the Saint Paul properties remaining in the market longer (HR = 0.86).  

```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ city, data=house)
plot( cox.zph(mcox) )
cox.zph( mcox )
```

We now look at the categorical list price variable. 

Kaplan-Meier c-log-log plot also has very narrow gap between the first and second list price groups, but a clearly unproportional gap in the lowest and the highest list price groups. The latter trend point to a strong evidence for the violoation of the PH assumption.

```{r}
KM = survfit(Surv(tom) ~ listedatprCat, data=house)
plot(KM,fun='cloglog',mark.time=FALSE,col=1:3, xlim = c(15,220))
```

As seen in the Kaplain-Meier c-log-log plot, the Schoenfeld residual plots illustrate that the PH assumption holds in the first two list price groups, while the opposite is true for the first and last list price groups. More specifically, the second group compared to the first group largely maintains the PH assumption throughout except at the very tip of the time frame. On the other hand, the highest list price group has visibly increasing (from large negative to positive) residuals, indicating a clear violation of the PH assumption. The residual output agrees in that the highest list price group has a non-constant positive HR with rho = 0.18 and a highly significant p-value. In other words, the hazard ratio is being underestimated as the residuals are increasing. The second group, on the other hand has rho close to 0 with insignificant p-value, indicating the validity of the PH assumption. 

```{r echo = FALSE}
(mcox = coxph(Surv(tom) ~ listedatprCat, data=house))
plot( cox.zph(mcox) )
cox.zph( mcox )
```

Finally, we look at the crime category variables. For this variable, we do not include the c-log-log for Kaplan-Meier because there are four groups with too small sample size for each group. 

```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ crimeCat2, data=house)
plot( cox.zph(mcox) )
cox.zph( mcox )
```

The slightly decresing residuals from the plots for the second crime group may make the PH assumption invalid. However, Schoenfeld residuals from both the third and the last crime group are constant throughout time, which indicate that the PH assumption is valid. In the residual fit output, all rhos are close to zero with insignificant p-values. This output demonstrates that the PH assumption is valid with all levels in the categorical crime variable. 



#### Multivariate Assessment of the PH Assumption

```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr), data=house)
# mcox = coxph(Surv(tom) ~ schdistCat + crimeCat2 + listedatprCat, data=house)
plot( cox.zph(mcox) )
cox.zph( mcox )
```

PH doesn't seem to hold. (Victor)
Before 84 days, list price has a strong impact.
After 84 days, list price is not impactful.



It seems that the PH assumption is valid for both school distance and list price, but not for crime categories. For school distance, the Schoenfeld residuals show a decreasing trends, while the list price Schoenfeld residuals increase with respect to time. The coefficients for school distance is consistent with the decreasing beta in the Schoenfeld residual plot, but that for list price is not consistent. !!!







# More Questions for Victor outside of rmd

!!! can we do this same procedure (mcox and plot of Schoenfeld) with multiple variables where some of these covariates are quantitative?

!!! are three PH assumption tests enough? (city, crimeCat, and priceCat)

!!! how does strata work for controlling instead of adding in new variables? doesn't adding in variables automatically control?

!!! when do we use strata over interaction? (crime cat and price)