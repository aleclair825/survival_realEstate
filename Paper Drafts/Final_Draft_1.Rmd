---
title: "Survival Analysis of Factors Affecting Time on Market for Twin Cities Homes"
author: "Nick McMullen, April Choi"
date: "April 20, 2018"
header-includes:
   - \usepackage{dcolumn}
   - \usepackage{tabularx}
output:
  pdf_document:
    pandoc_args:
    - -V
    - classoption=twocolumn
  html_document: default
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readr)
library(ggplot2)
library(survival)
library(survminer)
library(stargazer)

house <- read_csv("../Source/house_TC.csv")
house <- house %>% mutate(tom = ifelse(tom == 0, 1, tom),
                          prdiff_np = as.factor(prdiff_np))


# Creates Cox-Snell Plot:
CoxSnell = function(cs, status, xlim=NULL, ylim=NULL, main=NULL, sub=NULL) {
  kmcs=survfit(Surv(jitter(cs,amount=(max(cs)-min(cs))/1000),status)~1)$surv
  plot(log(-log(kmcs))~sort(log(cs)),xlab="log(Cox-Snell)",ylab="log(-log(S(Cox-Snell)))",xlim=xlim,ylim=ylim, main=main, sub=sub)
  abline(0,1,col='red') }

house$status <- rep(1, 311)

```

## 1 | Introduction


### 1.1 Background

The real estate market in the Twin Cities (Minneapolis and St. Paul, MN, USA), and many places across the United States, has been thriving on the economic recovery since the end of the Great Recession. While the current market is, to the casual observer, favorable to sellers some houses in Twin Cities still take a surprisingly long time to sell. We will investigate the characteristics that impact time on market (TOM) for houses in the Twin Cities through a survival analysis, or time-to-event, framework.


### 1.2 Review of Literature

\textbf{Price}

One of the most obvious factors that may influence TOM for any house is price. A high price may scare potential buyers away, while a low price might invite skepticism or a long bidding war. Moreover, a high price limits the number of potential buyers even if the price appropriately reflects the quality of the property. The "right" pricing decision is a difficult one to make for sellers and agents, but reaching an equilibrium between buyer and seller satisfaction may be the best way to minimize TOM. Cheng, Lin, and Liu (2008) developed a closed-form formula to uncover the theoretical relationship between price and TOM. They aim to describe the marginal benefit of keeping a house on the market longer.

The authors used house sales data from Fannie Mae and Freddie Mac, U.S. federal mortgage agencies, and identified a nonlinear positive relationship between price and TOM. They approached this analysis by assuming that a buyer and seller arrive at an agreed upon price following the Poisson processes at rate $\lambda$. While utilizing methods from Bond et al. (2007), they investiaged some assumptions about the shape of TOM data, including normal, chi-square, Weibull, and exponential distributions. Like Bond et al. (2007), Cheng, Lin, and Liu (2008) found that the exponential distribution best fit the TOM data. 

The findings from Cheng, Lin, and Liu's (2008) investigation was that marginal benefit on sale price decreases after each offer that is made on a house. As a house's price approaches equilibrium between seller and buyer satisfaction, it does the seller little good to leave the house on the market longer.

\textbf{Duration Dependence}

Another interesting question regarding TOM is how the probability of sale changes with time. Thomas W. Zuehlke (1987) conducted research on this very topic. He used 290 single family detached homes obtained from a 1982 multiple listing service (MLS) book in Tallahassee, FL, USA and observed how likely each house was to sell based on its vacancy status. Zuehlke utilized a Weibull hazard model to compare the two and found that sellers of vacant houses have stronger incentives to reduce prices faster than those of occupied houses. Thus, Zuehlke finds that vacant houses tend to exhibit positive duration dependence, while occupied homes show little evidence of duration dependence. 

Motivated by a Massachusetts state policy adopted in 2006 that prohibits sellers from resetting their home's TOM by relisting, Tucker, Zhang, and Zhu (2013) also investigated the impact of TOM on sale price. The authors agree that longer TOM is negatively associated with buyer perception, which lines up with the Massachusetts relisting policy. To investigate if TOM was indeed a significant deterrent for buyers looking at an otherwise appealing house, the authors analyzed the TOM for homes before and after the enactment of the policy. They obtained listings data for residential properties on the market between January 2005 and June 2007 from two MLSs: MLS-PIN, which serves Massachusetts, and the State-Wide Rhode Island MLS. Their analysis consisted of three groupings of homes: listed and sold before the policy change, listed before and sold after, and listed and sold after. The authors utilized simple linear regression between the three groups and found that the homes listed before the policy and sold after were most severely impacted, resulting in an average sale price reduction of $16,000. 

\textbf{Listing Price Changes}

Listing price changes may also affect the TOM for a house. A listing price change could attract more attention to a house on the market, but could also indicate a longer TOM. John R. Knight (2002) conducted an analysis on listing price changes, investigated which types of homes were most likely to go through multiple listing price changes, and which price changes tend to give the worst results for the seller.

Knight used 3490 detached single family homes that sold between January 1997 and December 1998 by Metroservices Inc. of Sacramento, CA, USA. He notes that price adjustment data is generally missing from TOM datasets, but his study incorporated the price changes into the analysis to examine the determinants of list price changes. He utilized a maximum likelihood probit model and found that the two most important determinants of price changes are TOM and initial markup. Atypical homes tend to not see significant price changes because there is little market precedent for price changes after a certain TOM. Knight's findings are consistent with previous research on pricing under demand uncertainty. 


### 1.3 Research Question (and mapping paragraph)

We are interested in investigating the factors that affect the TOM for a single family homes in the Twin Cities (Minneapolis and Saint Paul) that were sold between July 26, 2017 and February 1, 2018. Some variables of interest include the amount of recorded crime in a house's designated neighborhood and the proximity of a house to the nearest school. 

In the following sections, we outline our data collection and methods and provide a brief description of our assumptions. 

##2 | Data and Methods

### 2.1 Data and Sources

#### Real Estate Data

Our data represents a random sample of 311 single family homes in the Twin Cities that were sold between July 26th, 2017 and February 1st, 2018. A search of all recently sold homes in the area was conducted in the Coldwell Banker MLS and 311 unique addresses were randomly selected for the project. Some variables were scraped directly from the Coldwell Banker site, while others were manually inputted. 

#### Crime Data

We also obtained crime data beginning on January 1, 2015 from the government websites for the cities of Minneapolis and St. Paul. Each crime was matched with a neighborhood, aggregated into total neighborhood crime counts, and then joined with the house sales data. This addition will provide insight on the number of crimes that have been recorded over the past three years near each sold house. 

### 2.2 Variables

For all 311 observations, we collected unique addresses `address`, city of residence `city`, zip code `zip`, number of bedrooms `beds`, number of full bathrooms `bathf`, number of partial bathrooms `bathp`, number car garage `carg`, house squarefeet `sqft`, price the home was listed at `listedatpr`, price the home was sold for `soldatpr`, date the home was listed `listedatdate`, date the home was sold `soldatdate`, neighborhood the house is located `neighb`, distance to nearest school (mi.) `schdist`, and number of crimes that were recorded in that neighborhood beginning on January 1, 2015 `ncrime`. We also calculated the time on market `tom` for each house from list date to sale date amd included the property ID `pid` from the Coldwell Banker website. 

### 2.3 Assumptions

An essential assumption to our research is based on censoring. We intentionally collected our data from a sample of recently sold houses to limit censoring. If we were to take a true random sample of all houses listed for sale in the past $X$ number of years, we realize that a significant amount of right censoring could be present, because at the time of data collection some houses in our sample would have not been sold yet. We acknowledge that sampling from a set of recently sold houses may introduce some bias into our results - all recently sold houses in this particular date range (late January to early Februray 2018) may share certain unknown or unaccounted-for characteristics that made them sell. This bias is acceptable considering the convenience and added accuracy provided by uncensored data.

### 2.4 Methods

We first utilize nonparametric Kaplan-Meier curves to investigate relationships between time on market and certain variables like distance to the nearest school, crime in the home's neighborhood since 2015, list price, and municipal location. For crime and list price, it was necessary to create categorical variables to properly analyze their effect on time on market with some level of singificance and interpretability. 

Next, we construct univariate parametric accelerated failure time models for each of the variables mentioned previously. We deploy two distribution families - the Weibull and log-normal distributions - and assess which model fits the data better primarily using the (Akaike Information Criterion) AIC, with some assistance from Cox-Snell residual plots. We utilize this comparison approach throughout our analysis as it allows us to observe the impact of a parametric assumption and determine the overall significance of the models we are using, whether they are univariate or multivariate. 

We also fit a multivariate model using each of the variables mentioned above except city, as it appeared to have no significant relationship with time on market. Such an approach allowed us to control for multiple variables at once and see how each of their behavior changed in the presence of the others. With this multivariate strategy in mind, we also considered the possible interaction between list price and crime, as people living in higher crime areas may have to price their homes lower in order to sell. 

Finally, throughout our analysis we employed Cox's Proportional Hazards model as a comparison tool to parametric methods. Since these models assume proportional hazard ratios between the baseline and covariates included, we also asses each proportional hazard assumption using Schoenfeld residual plots.

##3 | Results

We begin our preliminary analysis by investigating the length of time that houses in the Twin Cities remain on the market after their preliminary listing date.

### 3.1 Non-Parametric (Kaplan-Meier) Survival Curve Estimates 

#### Proximity to Nearest School

Kaplan-Meier curves allow us to observe the general trends in the data, with time on market being the most important variable in the analysis. Our parametric analysis that follows will be informed by basic insights obtained from these Kaplan-Meier curves. 

First, we fit a Kaplan-Meier curve for time on market by distance from the nearest school. In order to do this, we identify the closest 50% of homes as "close" and the farthest 50% of homes as "far."

```{r echo=FALSE}

house$schdistCat <- cut(house$schdist, breaks = quantile(house$schdist, probs=c(0, .5, 1)))

KM0 <- survfit(Surv(tom) ~ schdistCat, conf.type="plain", data=house)

ggsurvplot(KM0, data=house, legend.labs=c("Near", "Far"), xlim=c(0,250)) + 
  labs(x = "Days on Market", y = "Survival Probability", title="Days on Market by Proximity to Nearest School")


```

There appears to be no difference based on distance to school. However, this may be due to the over-generalization (near vs. far) of school distance. This variable warrants further investigation. 

#### Crime 

Next, we fit a Kaplan-Meier curve for time on market based on number of crimes committed in that house's neighborhood since the beginning of 2015. 

```{r echo=FALSE}
house$crimeCat2 = cut(house$ncrime, breaks = c(0,250,2000,5000,10000))

# mean(house$tom)
# median(house$tom)
KM = survfit( Surv(tom) ~ crimeCat2, conf.type="plain" , data=house ) 
ggsurvplot(KM, data=house, legend.labs=c("0 to 250 crimes", "250 to 2000", "2000 to 5000", "5000 to 10000"), xlim=c(0,250)) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Days on Market by Crime Since 2015 Category")
```

We see that homes that fit into the second highest number of crimes category take the longest to sell, while homes in the lowest crime neighborhoods sell fastest. This progression seems logical, except for homes in the highest crime neighborhoods, which appear to sell generally the second fastest. This is likely because there are fewer houses (59) that fall into the highest crime category and thus the sample is not representative of the actual market. 

#### List Price

This Kaplan-Meier curve shows the time on market based on their list price. 

```{r echo=FALSE}
house$listedatprCat = cut(house$listedatpr, breaks = quantile(house$listedatpr, probs=c(0, .33, .67, 1)))

# mean(house$tom)
# median(house$tom)
KM1 = survfit( Surv(tom) ~ listedatprCat , conf.type="plain" , data=house ) 
ggsurvplot(KM1, data=house, legend.labs=c("price = 63,000 to 180,000", "180,000 to 275,000", "275,000 to 1,300,000")) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Days on Market by List Price Category")
```

Houses that fall into the highest price category appear to take the longest to sell, while houses in the middle price category appear to sell the fastest. 

#### Municipal Location

```{r echo=FALSE}
# mean(house$tom)
# median(house$tom)
KM2 = survfit( Surv(tom) ~ city , conf.type="plain" , data=house ) 
ggsurvplot(KM2, data=house, legend.labs=c("Minneapolis", "St. Paul")) +
  labs(x = "Days on Market", y = "Survival Probability", title = "Days on Market by City")
```

There doesn't apprear to be a huge difference in time to sale between homes in St. Paul and Minneapolis, but we see that in our data, St. Paul homes take slightly longer to sell based on this Kaplan-Meier curve. While this relationship may seem negligible, this small difference warrants further investigation in parametric models. 

Now that we have taken a brief look at Kaplan-Meier curves for these variables, we will create some models with parametric assumptions to verify or refute previously observed trends by assessing for significant relationships. 


### 3.2 Univariate Parametric Models

#### Proximity to Nearest School

The Kaplan-Meier curve shown in the previous section revealed what appears to be no difference in how long a house takes to sell based on its municipal designation. In order to verify the previous graphical findings, we create three parametric models to further assess the impact of school distance on time to sale. 

```{r include=FALSE}
mw = survreg( Surv(tom) ~ schdist , dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist , dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ schdist , data = house )

summary(mw) # the sign of schdist makes sense (positive) and it is significant
summary(mln) # the sign of schdist is negative and it is NOT significant
mcox # sign agrees with weibull and it is significant
```


The Weibull model indicates that the properties that are farther from schools have longer TOM than those closer to schools, with a significant p-value. However, the log-normal model yields the opposite result with an insignificant p-value. This result may be due to the inherent differences in the two models, rather than the school distance variable being insignificant. In fact, the Cox PH model agrees with the Weibull model in the variable's direction and p-value. According to the Cox PH model, the hazard ratio of school distance is 0.701, which means that the risk of being sold decreases by 30% for every one-mile increase in school distance. In other words, properties farther away from schools take longer to sell.


```{r include = FALSE}
# Create Cox-Snell residuals
CS_w = -log( 1 - pweibull(house$tom, 1/0.537, exp(4.443 + 0.246*house$schdist) ) )
CS_ln = -log( 1 - plnorm(house$tom, 4.3010 + -0.0313*house$schdist, 0.623) ) 
```

```{r echo=FALSE} 
CoxSnell( CS_w , house$status, main="Weibull School Distance C-S Resids" )
CoxSnell( CS_ln , house$status ,xlim=c(-7,5), main="Log-normal School Distance C-S Resids")
```

The log-normal Cox-Snell residuals appear to fit the model better since they fit the line with intercept 0 and slope 1 better. For the other following univariate models, the same trend holds so we elected to only show these Cox-Snell residual plot. 

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln

# The AIC for the Weibull model is 3242.878, and that for the log-normal model is 3258.564. Thus, we conclude that the Weibull model fits better than the log-normal model. 
```

AIC indicates that the Weibull model is a better fit. This contradiction between Cox-Snell residual plots and AIC could be attributed to different calculation methods, as Cox-Snell residuals do not consider number of parameters like AIC does. This is merely speculation, though. The actual reason for this contradition is unknown to us.

#### Crime 

```{r include=FALSE}
house$crimeCat2 = cut(house$ncrime, breaks = c(0,250,2000,5000,10000))

mw = survreg( Surv(tom) ~ crimeCat2, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ crimeCat2, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ crimeCat2, data = house )

summary(mw)
summary(mln)
mcox
```

Crime as a continuous variable was insignificant for all three models. Thus, we analyze the effect of crime as a categorical variable. Our categorical crime variable has four groups: crime count ranging from 0 to 250, 250 to 2000, 2000 to 5000, and 5000 to 10000.  

In the Weibull model, the 250-2000 crime group has TOM that is 14% longer than the 0-250 crime group, and the next group, the 2000-5000 crime group, has more than double the TOM of the previous group at 33%. While the p-value for 250-2000 crime group is at boarderline significance, that for the 2000-5000 crime group is significant at the 5% level. The fact that the houses in the neighborhoods with less crime (250-2000) would sell faster than those in the neighborhoods with more crime (2000-5000) makes sense since people generally prefer neighborhoods with less crime. 

On the other hand, the highest crime group (5000-10000) shows almost no difference in TOM compared to the lowest crime group, and its p-value is insignificant. This result is possibly due to the fact that properties located in high-crime neighborhoods tend to be more affordable. 

The Cox PH model agrees with the Weibull model. The hazard ratio for the 250-2000 crime group is approximately 19% less than that of the 0-250 crime group, and that for the (2000, 5000] group is approximately 36% less than that of the 0-250 crime group. Finally, the hazard ratio for the 5000-10000 crime group is only about 6% lower than the 0-250 crime group, again with insignificant p-value. The log-normal model too is insignificant. 

```{r include = FALSE}
CS_w = -log( 1 - pweibull(house$tom, 1/0.533, exp(4.45486375 +  0.13794492*(house$crimeCat2=="(250,2e+03]") + .28846076*(house$crimeCat2=="(2e+03,5e+03]") +   0.03853525*(house$crimeCat2=="(5e+03,1e+04]")     ) ) )
CS_ln = -log( 1 - plnorm(house$tom, 4.3010 + -0.0313*house$schdist, 0.623) ) 
```

```{r echo=FALSE, include=FALSE}
#CoxSnell( CS_w , house$status, main="Weibull Crime Category C-S Resids")
#CoxSnell( CS_ln , house$status, main="log-normal Crime Category C-S Resids")
```

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln
```

Again, the AIC indicates that the Weibull model is a better fit than the log-normal model. 


#### List Price

```{r include=FALSE}
mw = survreg( Surv(tom) ~ log(listedatpr), dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ log(listedatpr), dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ log(listedatpr), data = house )

summary(mw)
summary(mln)
mcox
```

```{r include = FALSE}
exp(0.120) #w
exp(0.189) #ln
```

Properties with higher list prices tend to have a longer TOM at the 5% significance level for both Weibull and the log-normal models. The effect is stronger with the log-normal model at 20% longer TOM (p=.0043) compared to 12% longer TOM for the Weibull model with a slightly lower significance (p=.0348). 

These results are consistent with the logic that a more expensive home will take longer to sell. The AIC yields a stronger evidence in support of the Weibull model over the log-normal model by a slight margin, which could indicate that the log-normal model is overplaying the impact that list price has on time to sale. 

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln
```

#### City

```{r include=FALSE}
mw = survreg( Surv(tom) ~ city, dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ city, dist = "lognormal" , data = house )
mcox = coxph( Surv(tom) ~ city, data = house )

summary(mw)
summary(mln)
mcox
```

```{r include = FALSE}
exp(0.101)
exp(0.0602)
```

In the Weibull model, city of Saint Paul has a positive coefficient with a borderline insignificant p-value, indicating that properties in Saint Paul on average has 11% longer tom compared to those in Minneapolis. The log-normal model, on the other hand, was not at all significant with a very small effect. The Cox PH is in line with the Weibull model with hazard ratio of Saint Paul to Minneapolis being 0.86. This hazard ratio illustrates that the risk of being sold for a house in Saint Paul is 86% that for a house in Minneapolis, which translates into a longer tom for a house in Saint Paul than that in Minneapolis. 


```{r include = FALSE}
mw$coefficients
mln$coefficients
# Create Cox-Snell residuals
house$cityn = ifelse(house$city == "Minneapolis", 1, 0)
CS_w = -log( 1 - pweibull(house$tom, 1/0.548101, exp(4.5292418 + 0.1006498*house$cityn  ))) 
CS_ln = -log( 1 - plnorm(house$tom, 4.25681878 + 0.06020683*house$cityn, 0.6219641 ) ) 
```

```{r echo=FALSE}
#CoxSnell( CS_w , house$status )
#CoxSnell( CS_ln , house$status )
```

```{r include = FALSE}
2*(3-mw$loglik[2]) # mw
2*(3-mln$loglik[2]) # mln
```

The AIC again shows that the Weibull model is a better fit for the data. This might be an indicator that there actually is a significant difference in time to sale between houses in Minneapolis and St. Paul, despite what appears to be a miniscule difference in the Kaplan-Meier curves. 



### 3.3 Multivariate Parametric Models

#### School Distance, Crime Category, and List Price Without Interaction Term (Original)

```{r include=FALSE}
mw = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , dist = "lognormal" , data = house )
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , data = house )

summary(mw) 
summary(mln) 
mcox
```

According to the Weibull model, all variables are significant with expected signs except for the highest crime category. As have seen in univariate models, school distance and list price variables predict positive correlation with TOM. In other words, homes with the higher list price or and those farther away from schools tend to stay on market longer. The directions with these two variables makes sense. Expensive houses are harder to sell because not many people are able to afford the house, and these houses may often be overpriced (higher than its appraisal value). On the other hand, houses closer to schools tend to be in more populated and desirable areas, so it should follow that houses closer to a school would sell faster. 

<<<<<<< HEAD
All crime categories predict longer TOM compared to the lowest crime category, which is mostly consistent with the univariate crime category analysis previously conducted. Specifically, the second crime group is more likely to stay on market longer compared to the lowest crime group in line with the univariate model. However, the TOM for the third crime group is less than double that for the second crime group, which is a weaker effect than what we saw in the univariate analysis. With respect to p-values, both the second and third group are now significant at the 5% level, and the p-value for the highest crime group improved by a factor of 3. For example, houses that belong to the second and third crime category on average have 21% and 29% longer TOM, respectively, compared to those in the lowest crime category. On the other hand, the highest crime category indicates only 11% longer TOM compared to the lowest crime group and an insignificant p-value.

Log-normal model had most of the coefficients in the right direction with worse significance, and the Cox PH model agrees with the Weibull model. 


=======
>>>>>>> df8f21ef19f88e1db7817d0216af364aff6416e5
```{r include=FALSE}
summary(mw)
mw$coefficients
edays_crimeCat2_1 = exp(2.712 + 0.1843770*mean(house$schdist) + 0.1309947*mean(log(house$listedatpr)))
edays_crimeCat2_2 = exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*1 + 0.2515044*0 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr)))
edays_crimeCat2_3 = exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*0 + 0.2515044*1 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr)))
edays_crimeCat2_4 = exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*0 + 0.2515044*0 + 0.1093053*1 + 0.1309947*mean(log(house$listedatpr)))

(tr_21 = edays_crimeCat2_2/edays_crimeCat2_1)
(tr_31 = edays_crimeCat2_3/edays_crimeCat2_1)
(tr_41 = edays_crimeCat2_4/edays_crimeCat2_1)

# time ratio matches with above
# check with Nick and Victor!!!
exp(0)
exp(0.1876134*1) # houses that belong to crime group 2 on average have 21% longer TOM compared to those that belong to crime group 1
exp(0.2515044*1)
exp(0.1093053*1)

crimeCat2_1 = function(x) 1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1309947*mean(log(house$listedatpr))))
crimeCat2_2 = function(x) 1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*1 + 0.2515044*0 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr))))
crimeCat2_3 = function(x) 1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*0 + 0.2515044*1 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr))))
crimeCat2_4 = function(x) 1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*0 + 0.2515044*0 + 0.1093053*1 + 0.1309947*mean(log(house$listedatpr))))

integrate(crimeCat2_1,0,Inf)
integrate(crimeCat2_2,0,Inf)
integrate(crimeCat2_3,0,Inf)
integrate(crimeCat2_4,0,Inf)

# Extra interpretation

# find Pr(days > 100) for the crime group 1
1-pweibull(100, 1/0.528, exp(2.712 + 0.1843770*mean(house$schdist) + 0.1309947*mean(log(house$listedatpr)))) # probability that the house will stay on market for 100 or more days if the house is in crime group 1 = 25%

# At what time point does the survival curve for the crime group 2fall to the same value as in above?
qweibull(1-0.2490305, 1/0.528, exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*1 + 0.2515044*0 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr))))

# the above is the same as the following:
100*exp(0.1876134*1) # how many days would it take a house in crime group 2 to reach 25% probability of staying on market for more than 100 days?
100*exp(0.2515044*1) # how many days would it take a house in crime group 3 to reach 25% probability of staying on market for more than 100 days?
100*exp(0.1093053*1) # how many days would it take a house in crime group 4 to reach 25% probability of staying on market for more than 100 days?

## Note: look at differences in days
```

Below is a survival comparison of the crime categories. 

```{r echo = FALSE}
# crime gp 1
curve(1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1309947*mean(log(house$listedatpr)))),col='black',xlim=c(0,150),ylab="Probability of Sale", xlab = "Days", main = "TOM for Crime Categories") 

# crime gp 2
curve(1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*1 + 0.2515044*0 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr)))),col='purple',xlim=c(0,150),ylab="Survival",add=TRUE)

# crime gp 3
curve(1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*0 + 0.2515044*1 + 0.1093053*0 + 0.1309947*mean(log(house$listedatpr)))),add=TRUE,col='blue',lty=1)

<<<<<<< HEAD
# crime gp 4
curve(1-pweibull(x,1/0.528,exp(2.712 + 0.1843770*mean(house$schdist) + 0.1876134*0 + 0.2515044*0 + 0.1093053*1 + 0.1309947*mean(log(house$listedatpr)))),add=TRUE,col='red',lty=1)

# time ratio
```
=======
The Weibull model has similar results to the univariate crime category analysis previously conducted. The second crime group is more likely to stay on market longer compared to the lowest crime group in line with the univariate model. However, the TOM for the third crime group is less than double that for the second crime group, which is a weaker effect than what we saw in the univariate analysis. With respect to p-values, both the second and third group are now significant at the 5% level, and the p-value for the highest crime group improved by a factor of 3. 
>>>>>>> df8f21ef19f88e1db7817d0216af364aff6416e5



#### Model Selection

Now, we select the model by first plotting the Cox-Snell residuals for the Weibull and log-normal models and then comparing the AIC calculations for each model. Utilizing both a graphical and analytical approach to assessing model fit will help ensure thorough vetting of models. 


*Cox-Snell Residuals*

```{r echo=FALSE, include=FALSE}
mln$coefficients
# Create Cox-Snell residuals
CS_w = -log( 1 - pweibull(house$tom, 1/0.532846, exp(2.7119300 + 0.1843770*house$schdist +
                                                       0.1876134*(house$crimeCat2=="(250,2e+03]") +
                                                       0.2515044*(house$crimeCat2=="(2e+03,5e+03]") +
                                                       0.1093053*(house$crimeCat2=="(5e+03,1e+04]") +
                                                       0.1309947*log(house$listedatpr))))
CS_ln = -log( 1 - plnorm(house$tom, 1.37373386 + -0.04454097*house$schdist + 0.09386602*(house$crimeCat2=="(250,2e+03]") +
                           0.22584417*(house$crimeCat2=="(2e+03,5e+03]") + 0.16964559*(house$crimeCat2=="(5e+03,1e+04]") +
                           0.22797669*log(house$listedatpr), 0.6088315)) 

```

```{r echo=FALSE}

# Make appropriate graph using CoxSnell function

CoxSnell( CS_w , house$status , main = "Cox-Snell Residuals", sub = "Weibull Model")
CoxSnell( CS_ln , house$status , main = "Cox-Snell Residuals", sub = "Log-Normal Model")
```

The log-normal model appears to perform better when evaluating performance graphically. However, the AIC prefers the Weibull model.

```{r echo=FALSE, include=FALSE}
2*(10-mw$loglik[2]) # mw
2*(10-mln$loglik[2]) # mln
```

*Summary of Cox Model*

```{r echo=FALSE, include=FALSE}
library(survminer)
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) , data = house )
mcox
```

```{r echo=FALSE, warning=FALSE}
ggforest(mcox, data = house)
```


#### School Distance, Crime Category, and List Price with Interaction Term 

```{r echo=FALSE, include=FALSE}
mw = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), dist = "weibull" , data = house )
mln = survreg( Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), dist = "lognormal" , data = house )
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), data = house )

summary(mw) 
summary(mln) 
mcox
```

Now, we include the interaction term between crime categories and list price. In the Weibull model with interaction, all terms are insignificant except for school distance, possibly due to significantly increased degrees of freedom. For interpretations, we pick three representative list price values to show how the probability of sale changes with respect to different crime categories at each of these list prices. The three prices are the 10th, 50th, and 90th percentile of the list price at \$129900,  \$219900, and \$480000, respectively. First, houses priced at the 10th percentile (\$129900) on average that belong to the second, third, and the highest crime category have 27%, 13%, and 7% longer TOM, respectively, compared to houses of the same price that belong to the lowest crime category. However, as the list price increases, we see that the houses in the second crime category have TOM that increases at a decreasing rate for each of the higher list prices, while those in both the third and last crime categories have TOM that increases at an increasing rate for each of the higher list prices. For example, houses priced at the 50th percentile (\$219900) project 19%, 24%, and 19% longer TOM for each incremental crime group compared to equally expensive houses in the lowest crime category. By the 90th percentile (\$480000), we see that houses in the second, third, and the last crime category have 9%, 43%, and 37% longer TOM, respectively, compared to equally expensive houses in the lowest crime category. These results suggest that cheapest houses have very small differences in TOM between houses in the lowest crime neighborhoods and those in the highest crime neighborhoods, possibly due to the fact that houses in the highest crime neighborhoods may be cheaper in price as well. On the other hand, the most expensive houses indicate the opposite; while houses in the first and second crime group do not differ much on TOM, houses in the third and the highest crime groups take longest to sell.

```{r include=FALSE} 
listedatpr_quant = quantile(house$listedatpr, c(0, 0.10, 0.5, 0.9, 1))

logpr_10 = log(listedatpr_quant[[2]])
logpr_50 = log(listedatpr_quant[[3]])
logpr_90 = log(listedatpr_quant[[4]])

# 10th percentile
### logpr_10 = 11.77452
exp(1.666-0.121*logpr_10)
exp(-1.984+.179*logpr_10)
exp(-2.118+.186*logpr_10)

# 50th percentile
### logpr_50 = 12.30093
exp(1.666-0.121*logpr_50)
exp(-1.984+.179*logpr_50)
exp(-2.118+.186*logpr_50)

# 90th percentile
### logpr_90 = 13.08154
exp(1.666-0.121*logpr_90)
exp(-1.984+.179*logpr_90)
exp(-2.118+.186*logpr_90)
```

*Summary of Cox Model*

```{r echo=FALSE, include=FALSE}
library(survminer)
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr) + crimeCat2:log(listedatpr), data = house )
mcox
```

```{r echo=FALSE, warning=FALSE}
<<<<<<< HEAD
ggforest(mcox, data = house)
=======
ggforest(fit, data = house)
```

```{r include = FALSE}
#stargazer(house[c(9,14,22),])
#stargazer(house[c(9,14,22),], summary=FALSE, rownames=FALSE)
stargazer(mw, mln, title="Results", align=TRUE)
#stargazer(mcox, title="Results", align=TRUE)
```



### 3.4 Testing the Cox PH Assumption

To test the PH assumption, we instead turn to examining the Kaplan-Meier c-log-log plot and the Schoenfeld residuals.


We first look at the PH assumption for the two cities: Saint Paul and Minneapolis. The very narrow gap in the two groups from the Kaplan-Meier c-log-log plot indicates essentially no difference between the two groups, providing a stronger evidence for the PH assumption.

```{r echo = FALSE, include=FALSE}
KM = survfit(Surv(tom) ~ city, data=house)
plot(KM,fun='cloglog',mark.time=FALSE,col=1:2, xlim = c(15,220))
>>>>>>> df8f21ef19f88e1db7817d0216af364aff6416e5
```


<<<<<<< HEAD
=======
```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ city, data=house)
plot( cox.zph(mcox) )
#cox.zph( mcox )
```
>>>>>>> df8f21ef19f88e1db7817d0216af364aff6416e5


<<<<<<< HEAD
=======
Kaplan-Meier c-log-log plot also has very narrow gap between the first and second list price groups, but a clearly unproportional gap in the lowest and the highest list price groups. The latter trend point to a strong evidence for the violoation of the PH assumption.

```{r include=FALSE}
KM = survfit(Surv(tom) ~ listedatprCat, data=house)
plot(KM,fun='cloglog',mark.time=FALSE,col=1:3, xlim = c(15,220))
```

As seen in the Kaplain-Meier c-log-log plot, the Schoenfeld residual plots illustrate that the PH assumption holds in the first two list price groups, while the opposite is true for the first and last list price groups. More specifically, the second group compared to the first group largely maintains the PH assumption throughout except at the very tip of the time frame. On the other hand, the highest list price group has visibly increasing (from large negative to positive) residuals, indicating a clear violation of the PH assumption. The residual output agrees in that the highest list price group has a non-constant positive HR with rho = 0.18 and a highly significant p-value. In other words, the hazard ratio is being underestimated as the residuals are increasing. The second group, on the other hand has rho close to 0 with insignificant p-value, indicating the validity of the PH assumption. 

```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ listedatprCat, data=house)
plot( cox.zph(mcox) )
#cox.zph( mcox )
```

Finally, we look at the crime category variables. For this variable, we do not include the c-log-log for Kaplan-Meier because there are four groups with too small sample size for each group. 

```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ crimeCat2, data=house)
plot( cox.zph(mcox) )
#cox.zph( mcox )
```

The slightly decresing residuals from the plots for the second crime group may make the PH assumption invalid. However, Schoenfeld residuals from both the third and the last crime group are constant throughout time, which indicate that the PH assumption is valid. In the residual fit output, all rhos are close to zero with insignificant p-values. This output demonstrates that the PH assumption is valid with all levels in the categorical crime variable. 
>>>>>>> df8f21ef19f88e1db7817d0216af364aff6416e5

### 3.4 Testing the Cox PH Assumption

To test the PH assumption, we instead turn to examining the Schoenfeld residuals.

#### Multivariate Assessment of the PH Assumption

```{r echo = FALSE}
mcox = coxph(Surv(tom) ~ schdist + crimeCat2 + log(listedatpr), data=house)
plot( cox.zph(mcox) )
cox.zph( mcox )
```

According to the Schoenfeld residuals, PH assumption seems to be valid for crime categories, while it does not hold for both school distance and list price. For school distance, the Schoenfeld residuals show a decreasing trends, while the list price Schoenfeld residuals increase with respect to time. More specifically, school distance has a strong positive effect in the beginning, which gradually decreases until about 45 days, and becomes ineffective afterwards. On the other hand, list price has a strong negative effect in the beginning, which slowly increases throughout the first three months and slightly increases afterwards. In other words, school distance mostly has a positive effect on TOM but the effect is valid only for the first 45 days, while list price mostly shows a negative effect on TOM which is valid only for the first three months. School distance showing positive trend for the first 45 days can be attributed to that most families with kids feel more urgency in moving to a new place. List price showing negative trend for the first three months may be due to wealth constraints as well as a possible defects in the property contingent on the duration on the market. This should not matter so much, as we are mainly interested in the effects in the first three months.



##4 Conclusions and Discussion

In summary, we observed some fascinating trends in the time a Twin Cities home spends on the market when controlling for variables such as distance to nearest school, list price, crime in neighborhood since 2015, and municipal location. 

First, our data indicate that houses closer to the nearest school tend to sell faster, likely due to the more convenient and/or central location. We also observed that houses priced higher tend to take longer to sell, likely because higher prices are self-selective of buyers. We also believe that houses with higher prices are more likely to be overpriced relative to their appraised value. We also observed that houses in neighborhoods with a higher number of crimes since the start of 2015 take longer to sell, with the exception of houses in the highest crime neighborhoods. This could be explained by houses in higher crime neighborhoods generally having lower prices. Finally, in a  broader look at time on market compared to municipal location, we did not observe a significant relationship between how long a home took to sell and whether a house is located in Minneapolis or St. Paul. 

Our Cox Proportional Hazards models for each variable revealed similar trends to our parametric models, though p-values were generally not significant with the exception of the second highest crime category, which showed a significantly decreased risk of selling the home compared to the lowest crime level. However, it is important to remember that insignificant p-values in a Cox Proportional Hazards model do not warrant ending the investigation since the proportional hazards assumption made in the model must be assessed. 

We considered that some of these variables might also behave differently in the presence of each other, so we created a multivariate model. Overall, this model verified our findings from the univariate models, including that more expensive houses tend to take longer to sell and houses in areas with higher crime also tend to stay on the market longer, though we did observe a weaker effect on TOM for the second-highest tier of neighborhood crimes. 

Our next thought was that an interaction may exist between the number of neighborhood crimes and list price, and our interaction model revealed in both the Weibull and log-normal cases that there is an interaction. We observed that the crime category that a house was associated with impacted the time on market for homes within the first 2 months of being listed on the market, and after that time the difference was negligible. The biggest effect was observed between the lowest level of crime and the next step up.  

The multivariate Cox Proportional Hazards model also verified our initial observations, including increased time on market when: distance from the nearest school increases, crime increases (especially for the second and third levels of crime), and the log of the list price increases. We also created the same proportional hazards assumption for the interaction model, which revealed some drastically different results with no significant p-values. Since not all of these p-values were significant, further investigation into the proportional hazards assumption was warranted. 

Our assessment of the proportional hazards assumptions generally resulted in declaring a valid proportional hazards assumption, with the exception of list price category, which showed an especially strong positive trend in Schoenfeld residuals for the most expensive group of houses. This indicated to us that the impact of a higher list price on a house diminishes over time. 

While our insights are generally not groundbreaking, they serve to produce an important base understanding for the interaction of the real estate market with the environment around it. We also believe that the results show some important aspects of consumer economic behavior. Hopefully our conclusions will help home buyers, sellers, and real estate agents alike to establish clear expectations for how long a home will remain on the market based on a variety of factors surrounding the listing. 

\clearpage

##5 Appendix

Weibull and log-normal multivariate model output results:

\begin{table}[!htbp] \centering 
  \caption{Results} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lD{.}{.}{-3} D{.}{.}{-3} } 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{2}{c}{tom} \\ 
\\[-1.8ex] & \multicolumn{1}{c}{\textit{Weibull}} & \multicolumn{1}{c}{\textit{survreg: lognormal}} \\ 
\\[-1.8ex] & \multicolumn{1}{c}{(1)} & \multicolumn{1}{c}{(2)}\\ 
\hline \\[-1.8ex] 
 schdist & 0.184^{**} & -0.045 \\ 
  & (0.090) & (0.105) \\ 
  & & \\ 
 crimeCat2(250,2e+03] & 0.188^{**} & 0.094 \\ 
  & (0.084) & (0.096) \\ 
  & & \\ 
 crimeCat2(2e+03,5e+03] & 0.252^{***} & 0.226^{**} \\ 
  & (0.087) & (0.097) \\ 
  & & \\ 
 crimeCat2(5e+03,1e+04] & 0.109 & 0.170 \\ 
  & (0.098) & (0.114) \\ 
  & & \\ 
 log(listedatpr) & 0.131^{**} & 0.228^{***} \\ 
  & (0.059) & (0.073) \\ 
  & & \\ 
 Constant & 2.712^{***} & 1.374 \\ 
  & (0.751) & (0.925) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Observations & \multicolumn{1}{c}{311} & \multicolumn{1}{c}{311} \\ 
Log Likelihood & \multicolumn{1}{c}{-1,611.420} & \multicolumn{1}{c}{-1,619.327} \\ 
$\chi^{2}$ (df = 5) & \multicolumn{1}{c}{22.426$^{***}$} & \multicolumn{1}{c}{13.995$^{**}$} \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table}

\clearpage

Weibull and log-normal interaction model output results:

\begin{table}[!htbp] \centering 
  \caption{Results} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lD{.}{.}{-3} D{.}{.}{-3} lp{5cm} }
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{2}{c}{tom} \\ 
\\[-1.8ex] & \multicolumn{1}{c}{\textit{Weibull}} & \multicolumn{1}{c}{\textit{survreg: lognormal}} \\ 
\\[-1.8ex] & \multicolumn{1}{c}{(1)} & \multicolumn{1}{c}{(2)}\\ 
\hline \\[-1.8ex] 
 schdist & 0.192^{**} & -0.057 \\ 
  & (0.089) & (0.104) \\ 
  & & \\ 
 crimeCat2(250,2e+03] & 1.666 & 5.359^{**} \\ 
  & (1.682) & (2.221) \\ 
  & & \\ 
 crimeCat2(2e+03,5e+03] & -1.984 & -0.942 \\ 
  & (2.024) & (2.408) \\ 
  & & \\ 
 crimeCat2(5e+03,1e+04] & -2.118 & 0.454 \\ 
  & (3.025) & (3.511) \\ 
  & & \\ 
 log(listedatpr) & 0.126 & 0.356^{***} \\ 
  & (0.098) & (0.131) \\ 
  & & \\ 
 crimeCat2(250,2e+03]:log(listedatpr) & -0.121 & -0.424^{**} \\ 
  & (0.135) & (0.178) \\ 
  & & \\ 
 crimeCat2(2e+03,5e+03]:log(listedatpr) & 0.179 & 0.096 \\ 
  & (0.161) & (0.192) \\ 
  & & \\ 
 crimeCat2(5e+03,1e+04]:log(listedatpr) & 0.186 & -0.016 \\ 
  & (0.250) & (0.290) \\ 
  & & \\ 
 Constant & 2.774^{**} & -0.238 \\ 
  & (1.239) & (1.661) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Observations & \multicolumn{1}{c}{311} & \multicolumn{1}{c}{311} \\ 
Log Likelihood & \multicolumn{1}{c}{-1,609.288} & \multicolumn{1}{c}{-1,614.500} \\ 
$\chi^{2}$ (df = 8) & \multicolumn{1}{c}{26.691$^{***}$} & \multicolumn{1}{c}{23.649$^{***}$} \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 




